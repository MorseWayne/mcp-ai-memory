services:
  # Qdrant 向量数据库
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant-vectordb
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-storage:/qdrant/storage
    environment:
      - QDRANT_API_KEY=${QDRANT_API_KEY:-}
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "timeout 1 bash -c '</dev/tcp/localhost/6333' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  # MCP AI Memory 服务
  mcp-ai-memory:
    image: mcp-ai-memory:latest
    build:
      context: .
      dockerfile: Dockerfile
      network: host
      args:
        HTTP_PROXY: ${HTTP_PROXY:-}
        HTTPS_PROXY: ${HTTPS_PROXY:-}
        ALL_PROXY: ${ALL_PROXY:-}
        NO_PROXY: ${NO_PROXY:-}
    container_name: mcp-ai-memory
    depends_on:
      qdrant:
        condition: service_healthy
    ports:
      - "8050:8050"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      TRANSPORT: sse
      HOST: 0.0.0.0
      PORT: 8050
      HTTP_PROXY: ${CONTAINER_HTTP_PROXY:-}
      HTTPS_PROXY: ${CONTAINER_HTTPS_PROXY:-}
      NO_PROXY: ${CONTAINER_NO_PROXY:-localhost,127.0.0.1,::1,host.docker.internal,qdrant,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16}
      LLM_PROVIDER: ${LLM_PROVIDER:-openai}
      LLM_BASE_URL: ${LLM_BASE_URL}
      LLM_API_KEY: ${LLM_API_KEY}
      LLM_MODEL: ${LLM_MODEL:-gpt-4o-mini}
      EMBEDDING_PROVIDER: ${EMBEDDING_PROVIDER:-openai}
      EMBEDDING_MODEL: ${EMBEDDING_MODEL:-text-embedding-3-small}
      EMBEDDING_DIMS: ${EMBEDDING_DIMS:-1536}
      VECTOR_STORE_PROVIDER: qdrant
      QDRANT_HOST: qdrant
      QDRANT_PORT: 6333
      QDRANT_COLLECTION: ${QDRANT_COLLECTION:-mem0_memories}
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "timeout 1 bash -c '</dev/tcp/localhost/8050' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

volumes:
  qdrant-storage:
    driver: local
